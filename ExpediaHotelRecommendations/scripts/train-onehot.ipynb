{
 "metadata": {
  "language": "lua",
  "name": "",
  "signature": "sha256:263e381cc44145bd4ba241cf0b13b4aa0aaad7547c8e691132dd7e9b934f2503"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'torch';\n",
      "require 'nn';\n",
      "require 'cunn';\n",
      "require 'cudnn';\n",
      "require 'cutorch';"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Split data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function split(str, pat)\n",
      "   local t = {}  -- NOTE: use {n = 0} in Lua-5.0\n",
      "   local fpat = \"(.-)\" .. pat\n",
      "   local last_end = 1\n",
      "   local s, e, cap = str:find(fpat, 1)\n",
      "   while s do\n",
      "      if s ~= 1 or cap ~= \"\" then\n",
      "         table.insert(t,cap)\n",
      "      end\n",
      "      last_end = e+1\n",
      "      s, e, cap = str:find(fpat, last_end)\n",
      "   end\n",
      "   if last_end <= #str then\n",
      "      cap = str:sub(last_end)\n",
      "      table.insert(t, cap)\n",
      "   end\n",
      "   return t\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Conver Data"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 1. To get week number"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function getYearBeginDayOfWeek(tm)\n",
      "  yearBegin = os.time{year=os.date(\"*t\",tm).year,month=1,day=1}\n",
      "  yearBeginDayOfWeek = tonumber(os.date(\"%w\",yearBegin))\n",
      "  -- sunday correct from 0 -> 7\n",
      "  if(yearBeginDayOfWeek == 0) then yearBeginDayOfWeek = 7 end\n",
      "  return yearBeginDayOfWeek\n",
      "end\n",
      "function getDayAdd(tm)\n",
      "  yearBeginDayOfWeek = getYearBeginDayOfWeek(tm)\n",
      "  if(yearBeginDayOfWeek < 5 ) then\n",
      "    -- first day is week 1\n",
      "    dayAdd = (yearBeginDayOfWeek - 2)\n",
      "  else \n",
      "    -- first day is week 52 or 53\n",
      "    dayAdd = (yearBeginDayOfWeek - 9)\n",
      "  end  \n",
      "  return dayAdd\n",
      "end\n",
      "function getWeekNumberOfYear(tm)\n",
      "  dayOfYear = os.date(\"%j\",tm)\n",
      "  dayAdd = getDayAdd(tm)\n",
      "  dayOfYearCorrected = dayOfYear + dayAdd\n",
      "  if(dayOfYearCorrected < 0) then\n",
      "    -- week of last year - decide if 52 or 53\n",
      "    lastYearBegin = os.time{year=os.date(\"*t\",tm).year-1,month=1,day=1}\n",
      "    lastYearEnd = os.time{year=os.date(\"*t\",tm).year-1,month=12,day=31}\n",
      "    dayAdd = getDayAdd(lastYearBegin)\n",
      "    dayOfYear = dayOfYear + os.date(\"%j\",lastYearEnd)\n",
      "    dayOfYearCorrected = dayOfYear + dayAdd\n",
      "  end  \n",
      "  weekNum = math.floor((dayOfYearCorrected) / 7) + 1\n",
      "  if( (dayOfYearCorrected > 0) and weekNum == 53) then\n",
      "    -- check if it is not considered as part of week 1 of next year\n",
      "    nextYearBegin = os.time{year=os.date(\"*t\",tm).year+1,month=1,day=1}\n",
      "    yearBeginDayOfWeek = getYearBeginDayOfWeek(nextYearBegin)\n",
      "    if(yearBeginDayOfWeek < 5 ) then\n",
      "      weekNum = 1\n",
      "    end  \n",
      "  end  \n",
      "  return weekNum\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function getDate(input)\n",
      "    dates = split(input, \"-\")\n",
      "    useDate = os.time{year=dates[1],month=dates[2],day=dates[3]}\n",
      "    weekNum = getWeekNumberOfYear(useDate)\n",
      "    return weekNum\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 2. onehot"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function onehot(tab, value, len)\n",
      "    if value == nil then\n",
      "        value = 0\n",
      "    end\n",
      "    for i=1,len do\n",
      "        if i==tonumber(value) then\n",
      "            table.insert(tab, 1)\n",
      "        else\n",
      "            table.insert(tab, 0)\n",
      "        end\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function onehot_range(data, value, len, step)\n",
      "    if value == nil then\n",
      "        value = 0\n",
      "    end\n",
      "    for i=1,len do\n",
      "        if tonumber(value) > i*tonumber(step) then\n",
      "            table.insert(data, 0)\n",
      "        else\n",
      "            table.insert(data, 1)\n",
      "            value = len * (step + 1)\n",
      "        end\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 3. binary"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function binary(data, value, len)\n",
      "    while len > 0 do\n",
      "        if value % 2 == 1 then\n",
      "            table.insert(data, 1)\n",
      "        else\n",
      "            table.insert(data, 0)\n",
      "        end\n",
      "        value = value / 2\n",
      "        len = len / 2\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### 4. dest info"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fileName = 'data/destinations.csv'\n",
      "\n",
      "info_sum = {}\n",
      "info_mean = {}\n",
      "info_std = {}\n",
      "N = 1\n",
      "head = 1\n",
      "for i=1,149 do table.insert(info_sum, 0) end\n",
      "for line in io.lines ( fileName ) do \n",
      "    if head == 1 then\n",
      "        head = 0\n",
      "    else\n",
      "        destdata = split(line, ',')\n",
      "        for j=1,149 do\n",
      "            info_sum[j] = info_sum[j] + tonumber(destdata[j+1])\n",
      "        end\n",
      "        N = N + 1\n",
      "    end\n",
      "end\n",
      "\n",
      "for i=1,149 do info_mean[i] = info_sum[i] / N end\n",
      "\n",
      "info_sum = {}\n",
      "N = 1\n",
      "head = 1\n",
      "for i=1,149 do table.insert(info_sum, 0) end\n",
      "for line in io.lines ( fileName ) do \n",
      "    if head == 1 then\n",
      "        head = 0\n",
      "    else\n",
      "        destdata = split(line, ',')\n",
      "        for j=1,149 do\n",
      "            info_sum[j] = info_sum[j] + (tonumber(destdata[j+1]) - info_mean[j]) * (tonumber(destdata[j+1]) - info_mean[j])\n",
      "        end\n",
      "        N = N + 1\n",
      "    end\n",
      "end\n",
      "\n",
      "for i=1,149 do info_std[i] = math.sqrt(info_sum[i] / N) end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "destInfo = {}\n",
      "i = 0\n",
      "head = 1\n",
      "nEmpty = 0\n",
      "empty_row = {}\n",
      "for j=1,149 do\n",
      "    table.insert(empty_row, 0)\n",
      "end\n",
      "for line in io.lines ( fileName ) do \n",
      "    if head == 1 then\n",
      "        head = 0\n",
      "    else\n",
      "        destdata = split(line, ',')\n",
      "        while tonumber(destdata[1]) ~= i do\n",
      "            --print('Empty line => destdata[1]: ' .. destdata[1], 'i: ' .. i)\n",
      "            table.insert(destInfo, empty_row)\n",
      "            i = i + 1\n",
      "            nEmpty = nEmpty + 1\n",
      "        end\n",
      "        row = {}\n",
      "        for j=1,149 do\n",
      "            table.insert(row, (destdata[j+1] - info_mean[j]) / info_std[j])\n",
      "        end\n",
      "        table.insert(destInfo, row)\n",
      "        if tonumber(destdata[1]) ~= i then\n",
      "            --print('Not Matched => destdata[1]: ' .. destdata[1], 'i: ' .. i)\n",
      "        end\n",
      "        i = i + 1\n",
      "    end\n",
      "end\n",
      "\n",
      "for i=1,1000 do table.insert(destInfo, empty_row) end\n",
      "print('nEmpty:' .. nEmpty)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 23,
       "text": [
        "nEmpty:2888\t\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function addDestinationInfo(data, value)\n",
      "    for i=1,149 do\n",
      "        table.insert(data, destInfo[value][i])\n",
      "    end\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Data normalize"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "distMean = 0\n",
      "distsum = 0\n",
      "data = loadData(1000)\n",
      "N = 0\n",
      "for i=1,1000 do \n",
      "    if data[i][4] ~= 0 then \n",
      "        N = N + 1; distsum = distsum + data[i][4] \n",
      "    end \n",
      "end\n",
      "distMean = distsum / N\n",
      "print(distsum)\n",
      "print(distMean)\n",
      "distsum = 0\n",
      "for i=1,1000 do \n",
      "    if data[i][4] ~= 0 then \n",
      "        N = N + 1; distsum = distsum + (data[i][4] -distMean)*(data[i][4] -distMean)\n",
      "    end \n",
      "end\n",
      "print(math.sqrt(distsum / N))\n",
      "function tableToOutput(dataTable, scalarTable)\n",
      "   local data, scalarLabels, labels\n",
      "   local quantity = #scalarTable\n",
      "   local size = #dataTable[1]\n",
      "   data = torch.Tensor(quantity, size)\n",
      "   scalarLabels = torch.LongTensor(quantity):fill(-1111)\n",
      "   for i=1,#dataTable do\n",
      "      for j=1,#dataTable[1] do\n",
      "         data[i][j] = dataTable[i][j]\n",
      "      end\n",
      "      scalarLabels[i] = scalarTable[i]\n",
      "   end\n",
      "   return data, scalarLabels\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "-14.6009543125\t\n",
        "-0.022742919489875\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 25,
       "text": [
        "0.96299504729414\t\n"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Convert input to data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function dataConvert(line)\n",
      "    if line == nil then\n",
      "        print('line is empty')\n",
      "    end\n",
      "    words = split(line, \",\")\n",
      "    data = {}\n",
      "    aa = split(words[1], ' ')[1]\n",
      "    table.insert(data, tonumber(getDate(aa))) --1\n",
      "    table.insert(data, getDate(words[12])) --12\n",
      "    table.insert(data, getDate(words[13])) --13\n",
      "    \n",
      "    if tonumber(words[7]) == nil then\n",
      "        table.insert(data, 0) -- distance\n",
      "    else\n",
      "        table.insert(data, (tonumber(words[7]) - 1800) / 1600) -- distance\n",
      "    end\n",
      "    table.insert(data, (words[9]-26)/26)\n",
      "    table.insert(data, (words[10]-26)/26)\n",
      "    table.insert(data, (words[20]-26)/26)\n",
      "    \n",
      "    --[[ onehot]]\n",
      "    onehot(data, words[2], 54)\n",
      "    onehot(data, words[3], 5)\n",
      "    onehot(data, words[4], 240)\n",
      "    onehot(data, words[5], 1028)\n",
      "    onehot(data, words[11], 11)\n",
      "    onehot(data, words[14], 10)\n",
      "    onehot(data, words[15], 10)\n",
      "    onehot(data, words[16], 9)\n",
      "    onehot(data, words[18], 10)\n",
      "    onehot(data, words[21], 7)\n",
      "    onehot(data, words[22], 213)\n",
      "    onehot(data, words[23], 2118)\n",
      "    --]]\n",
      "    \n",
      "    --[[ binary\n",
      "    binary(data, words[2], 54)\n",
      "    binary(data, words[3], 5)\n",
      "    binary(data, words[4], 240)\n",
      "    binary(data, words[5], 1028)\n",
      "    binary(data, words[11], 11)\n",
      "    binary(data, words[14], 10)\n",
      "    binary(data, words[15], 10)\n",
      "    binary(data, words[16], 9)\n",
      "    binary(data, words[18], 10)\n",
      "    binary(data, words[21], 7)\n",
      "    binary(data, words[22], 213)\n",
      "    binary(data, words[23], 2118)        \n",
      "    --]]\n",
      "    \n",
      "    --onehot_range(data, words[7], 100, 12408/99)\n",
      "    \n",
      "    -- destination information (17)\n",
      "    addDestinationInfo(data, tonumber(words[17]))\n",
      "    \n",
      "    return data\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 31
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Build model"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = nn.Sequential()\n",
      "-- for onehot inputsize: 3871\n",
      "model:add(nn.Linear(3871, 5000))\n",
      "model:add(nn.Threshold(0, 1e-6))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5000, 5000))\n",
      "model:add(nn.Threshold(0, 1e-6))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5000, 5000))\n",
      "model:add(nn.Threshold(0, 1e-6))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5000, 5000))\n",
      "model:add(nn.Threshold(0, 1e-6))\n",
      "model:add(nn.ReLU())\n",
      "model:add(nn.Linear(5000, 100))\n",
      "model = model:cuda()\n",
      "\n",
      "params, grad_params = model:getParameters()\n",
      "crit = nn.CrossEntropyCriterion()\n",
      "crit = crit:cuda()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Load Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function loadData(quantity)\n",
      "    dataTable = {}\n",
      "    labTable = {}\n",
      "    for i=1,quantity do\n",
      "        local class = torch.random(0,99)\n",
      "        local fname = 'data/train/train_' .. string.format( \"%02d\", class ) .. '.csv'\n",
      "        file = io.open(fname, \"r\")\n",
      "        picked = torch.random(1,file:seek(\"end\")-200)\n",
      "        file:seek(\"set\", picked)\n",
      "        file:read()\n",
      "        table.insert(dataTable, dataConvert(file:read()))\n",
      "        table.insert(labTable, class+1)\n",
      "        io.close(file)\n",
      "    end\n",
      "    local data, label = tableToOutput(dataTable, labTable)\n",
      "    return data, label\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Print"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "function PrintCM()\n",
      "  local loss = 0\n",
      "  local top1 = 0\n",
      "  model:evaluate()\n",
      "  local x, y = loadData(1000)\n",
      "  x = x:cuda()\n",
      "  y = y:cuda()\n",
      "  local N = y:size(1)\n",
      "  local scores = model:forward(x)\n",
      "  loss = loss + crit:forward(scores, y)\n",
      "\n",
      "  local pred = scores:float()\n",
      "  local _, pred_sorted = pred:sort(2, true)\n",
      "\n",
      "  for i=1,N do\n",
      "    if pred_sorted[i][1] == y[i] then\n",
      "      top1 = top1 + 1\n",
      "    end\n",
      "  end\n",
      "  print(\"loss: \" .. loss, \"train accuracy: \" .. top1 * 100 / N .. '%')\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Check Size"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "local x,y = loadData(2)\n",
      "print(x:size())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 32,
       "text": [
        "    2\n",
        " 3871\n",
        "[torch.LongStorage of size 2]\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 32
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Training"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "require 'optim';"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "-- Loss function that we pass to an optim method\n",
      "function f(w)\n",
      "  assert(w == params)\n",
      "  grad_params:zero()\n",
      "\n",
      "  --local x, y = loader:nextBatch('train')\n",
      "  local x, y = loadData(2000)\n",
      "  \n",
      "  x = x:cuda()\n",
      "  y = y:cuda()\n",
      "  local scores = model:forward(x)\n",
      "  local loss = crit:forward(scores, y)\n",
      "  local grad_scores = crit:backward(scores, y)\n",
      "  model:backward(x, grad_scores)\n",
      "\n",
      "  grad_params:clamp(-5, 5)\n",
      "\n",
      "  return loss, grad_params\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model:training()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "learningRate = 1e-3\n",
      "lr_decay_factor = 0.5\n",
      "lr_decay_every = 10\n",
      "print_every = 5\n",
      "optim_config = {learningRate = 0.5}\n",
      "num_iterations = 1000\n",
      "epoch = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i = 0, num_iterations do\n",
      "    if epoch % lr_decay_every == 0 then\n",
      "        old_lr = learningRate\n",
      "        optim_config = {learningRate = old_lr * lr_decay_factor}\n",
      "    end\n",
      "    \n",
      "    local _, loss = optim.adam(f, params, optim_config)\n",
      "    if i % print_every == 0 then\n",
      "        model:evaluate()\n",
      "        PrintCM()\n",
      "        model:training()\n",
      "    end\n",
      "    epoch = epoch + 1\n",
      "end"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 4726170583040\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 511655968\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7550157\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 8975313\ttrain accuracy: 0.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 22865314\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 8641796\ttrain accuracy: 0.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7792061.5\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 36767752\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 5901508\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10612739\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7209739\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 4476548\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3134709.5\ttrain accuracy: 0.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 5618141.5\ttrain accuracy: 0.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 4766387.5\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 4419389\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 20123936\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10612662\t"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "train accuracy: 0.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3850262\ttrain accuracy: 0.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2454761\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 13165697\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2787248.25\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7210969\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2727787\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10770405\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2657538.5\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1763435.375\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1343312.25\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10421832\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1469002.5\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1655675\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7181224\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1672967.375\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1351657.875\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3092174.25\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1709195.625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 885127.625\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 709541.3125\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1036412.8125\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2182365\ttrain accuracy: 1.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 749222.5\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 697597.4375\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1024850.375\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 690561\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 978579.0625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1163679.875\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 924659.875\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 633270.75\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1303555.125\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3036917.25\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1453138.75\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 1709401.25\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 519196\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 701209.1875\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 468578.65625\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 461916.53125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 615284.5\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 485523.28125\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 2457125.5\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7071782.5\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 684605.1875\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 579176.125\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 550619.5\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 286848.03125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 343063.125\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 466148.21875\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 232502.265625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 551975.875\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 193918.46875\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 228623.359375\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 233281.515625\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 233857.875\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 166840.203125\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 265242.34375\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 196619.96875\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 177934.546875\ttrain accuracy: 2%\t"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 223442.296875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 522107.1875\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 317845.9375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 197028.59375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 343003.25\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 705189.1875\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 196408.8125\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 150393.859375\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 172293.796875\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 223659.46875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 290683.5625\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 162143.9375\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 137902.59375\ttrain accuracy: 2.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 129009.8671875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 170580.859375\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 218743.796875\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 203057.703125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3954865.75\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 122363.125\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 131002.4296875\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 59856.0234375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 112797.1328125\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 82006.4140625\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 104542.3515625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 98283.9375\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 113369.0078125\ttrain accuracy: 1.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 175100.75\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 80795.90625\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 81593.9140625\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 113767.25\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 79581.0546875\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 56333.60546875\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 67891.8671875\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 155785.78125\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 54376.47265625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 84717.5078125\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 47374.51171875\ttrain accuracy: 2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 54919.2890625\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 61583.73046875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 66618.4296875\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 66082.625\ttrain accuracy: 2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 77510.140625\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 64611.05859375\ttrain accuracy: 1.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 50571.2265625\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 43169.09375\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 29011.880859375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 48915.3984375\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 99441.8046875\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 34781.171875\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 43053.92578125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 59062.78515625\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 41239.83984375\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 40956.22265625\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 50892.0703125\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 37490.34375\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 83673.78125\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 42691.015625\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 27896.220703125\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 47917.02734375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 35620.32421875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 34133.32421875\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 40017.1796875\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 39871.23828125\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 25961.888671875\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 16757.580078125\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 32421.548828125\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 18981.62109375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 26363.673828125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 16959.884765625\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 28777.111328125\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 33120.0390625\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 20828.09765625\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 23368.072265625\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 18918.544921875\ttrain accuracy: 0.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 23877.4375\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 22476.990234375\ttrain accuracy: 1.3%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 20010.224609375\ttrain accuracy: 1.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 18593.798828125\ttrain accuracy: 0.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 35022.421875\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 25196.76171875\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 88429.125\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 24280.03125\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 18711.169921875\ttrain accuracy: 2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 78480.8046875\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 176159.5625\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 21326.46875\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 20249.736328125\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 14663.756835938\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 24053.8828125\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 19531.55859375\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11951.921875\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10489.365234375\ttrain accuracy: 0.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 13942.34375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 13456.0859375\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 9969.7802734375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11714.274414062\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 14721.741210938\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11100.211914062\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 14462.880859375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 9481.1943359375\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 13649.387695312\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 9240.919921875\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 15329.244140625\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10487.596679688\ttrain accuracy: 1.1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 6680.9912109375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11370.826171875\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7899.9428710938\ttrain accuracy: 1.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10100.013671875\ttrain accuracy: 1.5%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 9160.232421875\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11938.809570312\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 12374.798828125\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 8900.4931640625\ttrain accuracy: 1.4%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10232.685546875\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 16399.234375\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 16079.26171875\ttrain accuracy: 1.8%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 12395.797851562\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 5682.5766601562\ttrain accuracy: 0.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 9705.0380859375\ttrain accuracy: 1%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 21333.92578125\ttrain accuracy: 1.6%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7461.8720703125\ttrain accuracy: 0.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 10218.267578125\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 7506.8369140625\ttrain accuracy: 1.7%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 6665.6796875\ttrain accuracy: 0.9%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 3972.533203125\ttrain accuracy: 1.2%\t\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "loss: 11313.375976562\ttrain accuracy: 0.4%\t\n"
       ]
      }
     ],
     "prompt_number": 35
    }
   ],
   "metadata": {}
  }
 ]
}